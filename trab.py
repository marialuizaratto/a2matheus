pip install wikipedia

import streamlit as st
import pandas as pd
import wikipedia

import requests
from bs4 import BeautifulSoup

st.set_page_config(page_title="Afinidade Legislativa", layout="centered")

st.title("ðŸ“Š Afinidade Legislativa com Deputados Federais")
st.write("""
Este aplicativo compara suas opiniÃµes com votaÃ§Ãµes reais da CÃ¢mara dos Deputados. 
Este aplicativo compara suas opiniÃµes com votaÃ§Ãµes reais da CÃ¢mara dos Deputados.

A partir das suas respostas, identificamos quais deputados do seu estado votam de forma mais alinhada com vocÃª.
""")

@@ -22,16 +21,9 @@ def carregar_dados():

perguntas = {
    "345311-270": "VocÃª concorda com o Marco Temporal para demarcaÃ§Ã£o de terras indÃ­genas?",
    "2438467-47": "VocÃª apoia a criaÃ§Ã£o do Dia Nacional para a AÃ§Ã£o ClimÃ¡tica?",
    "2207613-167": "VocÃª Ã© contra a privatizaÃ§Ã£o de empresas e o aumento de custos no saneamento bÃ¡sico?",
    "264726-144": "VocÃª apoia o aumento de pena para porte ilegal de arma?",
    "604557-205": "VocÃª apoia a Lei do Mar, que regula a exploraÃ§Ã£o sustentÃ¡vel dos recursos marÃ­timos?",
    "2417025-55": "VocÃª concorda que uma pessoa que ganha 2 salÃ¡rios mÃ­nimos deve pagar imposto de renda?",
    "2231632-97": "VocÃª concorda que documentos pÃºblicos devem usar linguagem acessÃ­vel?",
    "2345281-63": "VocÃª concorda que mulheres tÃªm direito Ã  cirurgia reparadora das mamas apÃ³s cÃ¢ncer pelo SUS?",
    "2078693-87": "VocÃª apoia repasses federais mesmo para municÃ­pios inadimplentes, se for para combater a violÃªncia contra a mulher?",
    "2310025-56": "VocÃª apoia a Lei Aldir Blanc de incentivo Ã  cultura?",
}


ufs_disponiveis = sorted(df["uf"].dropna().unique())
@@ -55,12 +47,24 @@ def carregar_dados():


def buscar_wikipedia(nome):
    wikipedia.set_lang("pt")
    url = f"https://pt.wikipedia.org/wiki/{nome.replace(' ', '_')}"
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        return wikipedia.summary(nome, sentences=3)
    except Exception:
        try:
            response = requests.get(url, headers=headers)
            if response.status_code != 200:
                return "NÃ£o foi possÃ­vel encontrar uma descriÃ§Ã£o na Wikipedia."

            soup = BeautifulSoup(response.text, 'html.parser')
            paragrafo = soup.select_one("p")

            if paragrafo and paragrafo.text.strip():
                return paragrafo.text.strip()
            else:
                return "PÃ¡gina encontrada, mas sem resumo disponÃ­vel."
        except Exception as e:
            return f"Erro ao acessar Wikipedia: {e}"

if st.button("Ver afinidade com deputados do seu estado"):
    st.subheader("ðŸ† PÃ³dio de afinidade legislativa")
@@ -93,7 +97,6 @@ def buscar_wikipedia(nome):
        for i, (dep, score) in enumerate(ranking[:3], 1):
            st.write(f"{i}Âº lugar: {dep} â€” {score} pontos")

        # 1Âº lugar: mostrar descriÃ§Ã£o e como votou
        dep_vencedor = ranking[0][0]
        nome_vencedor = dep_vencedor.split(" (")[0]

@@ -105,8 +108,8 @@ def buscar_wikipedia(nome):
        votos_vencedor = df[(df["nome"] == nome_vencedor) & (df["uf"] == uf_usuario)]

        for id_vot, pergunta in perguntas.items():
            voto = votos_vencedor[votos_vencedor["id_votacao"] == id_vot]["voto"].values
            voto_final = voto[0] if len(voto) > 0 else "Sem registro"
            voto_linha = votos_vencedor[votos_vencedor["id_votacao"] == id_vot]
            voto_final = voto_linha["voto"].iloc[0] if not voto_linha.empty else "Sem registro"
            st.markdown(f"- **{pergunta}** â†’ {voto_final}")
    else:
        st.info("Nenhum deputado encontrado para esse estado.")
